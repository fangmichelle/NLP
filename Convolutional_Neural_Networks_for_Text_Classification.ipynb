{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional Neural Networks for Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sGKifyWQ6S",
        "colab_type": "text"
      },
      "source": [
        "#Convolutional Neural Networks for Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw6pcjjzWdqI",
        "colab_type": "text"
      },
      "source": [
        "You will be implementing the _forward pass_ and _backpropagation_ for a convolutional neural network with sparse inputs for text classification. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hiu0tLm9Wnah",
        "colab_type": "text"
      },
      "source": [
        "## The setup\n",
        "Let's define parameters for the Convolutional Neural Network. You do not need to modify them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "284_yXERWZFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# window size for the CNN\n",
        "width = 2\n",
        "\n",
        "# number of filters\n",
        "F = 100\n",
        "\n",
        "# learning rate\n",
        "alpha = 1e-1\n",
        "\n",
        "# vocabsize: size of the total vocabulary\n",
        "vocabsize = 10000\n",
        "\n",
        "# vocab: the vocabulary dictionary with the word as key and its index as value\n",
        "# the input will be transformed into respective positional indices using the vocab dictionary\n",
        "# as the input for the forward and backward algorithm\n",
        "# e.g. if vocab = {'a': 0, 'simple': 1, 'sentence': 2} and the training data is\n",
        "# \"a simple simple sentence a\",\n",
        "# the input to the forward and backward algorithm will be [0,1,1,2,0]\n",
        "vocab = {}\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "# U and V are weight vectors of the hidden layer\n",
        "# U: a matrix of weights of all inputs for the first\n",
        "# hidden layer for all F filters in the\n",
        "# where each filter has the size of vocabsize by width (window size)\n",
        "# U[i, j, k] represents the weight of filter u_j\n",
        "# for word with vocab[word] = i when the word is\n",
        "# at the position k of the sliding window\n",
        "# e.g. for the example, \"a simple simple sentence a\",\n",
        "# if the window size is 4 and we are looking at the first sliding window\n",
        "# of the 9th filter, the weight for the last \"sentence\" will be U[2, 8, 3]\n",
        "# i.e U[index of the word in vocab, index of the filter, position of the word in that sliding window]\n",
        "U = np.random.normal(loc=0, scale=0.01, size=(vocabsize, F, width))\n",
        "\n",
        "# V: the the weight vector of the F filter outputs (after max pooling)\n",
        "# that will produce the output, i.e. o = sigmoid(V*h)\n",
        "V = np.random.normal(loc=0, scale=0.01, size=(F))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw0w-FwHXfH_",
        "colab_type": "text"
      },
      "source": [
        "Let's define some utility functions that may be useful. You don't need to modify them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNxHBX7WrYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    helper function that computes the sigmoid function\n",
        "    \"\"\"\n",
        "    return 1. / (1 + math.exp(-x))\n",
        "\n",
        "\n",
        "def read_vocab(filename):\n",
        "    \"\"\"\n",
        "    helper function that builds up the vocab dictionary for input transformation\n",
        "    \"\"\"\n",
        "    file = open(filename)\n",
        "    for line in file:\n",
        "        cols = line.rstrip().split(\"\\t\")\n",
        "        word = cols[0]\n",
        "        idd = int(cols[1])\n",
        "        vocab[word] = idd\n",
        "    file.close()\n",
        "\n",
        "\n",
        "def read_data(filename):\n",
        "    \"\"\"\n",
        "    :param filename: the name of the file\n",
        "    :return: list of tuple ([word index list], label)\n",
        "    as input for the forward and backward function\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    file = open(filename)\n",
        "    for line in file:\n",
        "        cols = line.rstrip().split(\"\\t\")\n",
        "        label = int(cols[0])\n",
        "        words = cols[1].split(\" \")\n",
        "        w_int = []\n",
        "        for w in words:\n",
        "            # skip the unknown words\n",
        "            if w in vocab:\n",
        "                w_int.append(vocab[w])\n",
        "        data.append((w_int, label))\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "def train():\n",
        "    \"\"\"\n",
        "    main caller function that reads in the names of the files\n",
        "    and train the CNN to classify movie reviews\n",
        "    \"\"\"\n",
        "    vocabFile = \"vocab.txt\"\n",
        "    trainingFile = \"movie_reviews.train\"\n",
        "    testFile = \"movie_reviews.dev\"\n",
        "\n",
        "    read_vocab(vocabFile)\n",
        "    training_data = read_data(trainingFile)\n",
        "    test_data = read_data(testFile)\n",
        "\n",
        "    for i in range(50):\n",
        "        # confusion matrix showing the accuracy of the algorithm\n",
        "        confusion_training = np.zeros((2, 2))\n",
        "        confusion_validation = np.zeros((2, 2))\n",
        "\n",
        "        for (data, label) in training_data:\n",
        "            # back propagation to update weights for both U and V\n",
        "            backward(data, label)\n",
        "\n",
        "            # calculate forward and evaluate\n",
        "            prob = forward(data)[\"prob\"]\n",
        "            pred = 1 if prob > .5 else 0\n",
        "            confusion_training[pred, label] += 1\n",
        "\n",
        "        for (data, label) in test_data:\n",
        "            # calculate forward and evaluate\n",
        "            prob = forward(data)[\"prob\"]\n",
        "            pred = 1 if prob > .5 else 0\n",
        "            confusion_validation[pred, label] += 1\n",
        "\n",
        "        print(\"Epoch: {} \\tDev accuracy: {:.3f}\"\n",
        "            .format(\n",
        "            i,\n",
        "            np.sum(np.diag(confusion_validation)) / np.sum(confusion_validation)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev6O33rf25Ko",
        "colab_type": "text"
      },
      "source": [
        "And finally, we'll download the data. We'll be doing sentiment analysis on a dataset of movie reviews, so we'll need 3 files - a vocabulary file, a file with a training set of movie reviews, and a development set containing different reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Q7-x7-2_d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_2/vocab.txt \n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_2/movie_reviews.dev\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_2/movie_reviews.train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5I1QY3NXnkX",
        "colab_type": "text"
      },
      "source": [
        "## 1. Forward\n",
        "\n",
        "Given the parameters and definition of the CNN model (ยง2 of HW), complete the Forward Function to calculate _o_ (the probability of the positive class) for an input text. You may not import any additional libraries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR7JOqL9XjZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(word_indices):\n",
        "    \"\"\"\n",
        "    :param word_indices: a list of word indices, i.e. idx = vocab[word]\n",
        "    :return: a result dictionary containing 3 items -\n",
        "    result['prob']: output of the CNN algorithm.\n",
        "    result['h']: the hidden layer output after max pooling, h = [h1, ..., hF]\n",
        "    result['hid']: argmax of F filters, e.g. j of x_j\n",
        "    e.g. for the ith filter u_i, tanh(word[hid[i], hid[i] + width]*u_i) = max(h_i)\n",
        "    \"\"\"\n",
        "\n",
        "    h = np.zeros(F, dtype=float)\n",
        "    hid = np.zeros(F, dtype=int)\n",
        "    prob = 0.0\n",
        "\n",
        "    # step 1. compute h and hid\n",
        "    # loop through the input data of word indices and\n",
        "    # keep track of the max filtered value h_i and its position index x_j\n",
        "    # h_i = max(tanh(weighted sum of all words in a given window)) over all windows for u_i\n",
        "    \"\"\"\n",
        "    Type your code below\n",
        "    \"\"\"\n",
        "    #p = np.zeros((len(word_indices)-1, F), dtype=float)\n",
        "\n",
        "    #for i in range(len(word_indices) - 1):\n",
        "      #p[i] = np.tanh(U[word_indices[i],:,0]) + np.tanh(U[word_indices[i+1],:,1])\n",
        "\n",
        "    #h = [max(p[:,f]) for f in range(F)]\n",
        "    #hid = [np.argmax(p[:,f]) for f in range(F)]\n",
        "    \n",
        "    for filt in range(F):\n",
        "      p = []\n",
        "      for i in range(len(word_indices) - 1):\n",
        "        # index U to create p_i\n",
        "        # for k in range(width):\n",
        "        p_i = np.tanh(U[word_indices[i],filt,0]) + np.tanh(U[word_indices[i+1],filt,1])\n",
        "        p.append(p_i)\n",
        "      h[filt] = max(p)\n",
        "      hid[filt] = np.argmax(p)\n",
        "\n",
        "    # step 2. compute probability\n",
        "    # once h and hid are computed, compute the probabiliy by sigmoid(h^TV)\n",
        "    \n",
        "    \"\"\"\n",
        "    Type your code below\n",
        "    \"\"\"\n",
        "\n",
        "    # prob = sigmoid(h.transpose().dot(V))\n",
        "    prob = sigmoid(V.T.dot(h))\n",
        "\n",
        "    # step 3. return result\n",
        "    return {\"prob\": prob, \"h\": h, \"hid\": hid}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E74JyTjkXvqK",
        "colab_type": "text"
      },
      "source": [
        "## 2. Backward\n",
        "\n",
        "Using the gradient update equations for V (ยง3 in HW) and U (ยง3.1), implement the updates for U and V in the backward function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT8hRNr0XsVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward(word_indices, true_label):\n",
        "    \"\"\"\n",
        "    :param word_indices: a list of word indices, i.e. idx = vocab[word]\n",
        "    :param true_label: true label (0, 1) of the movie reviews\n",
        "    :return: None\n",
        "    update weight matrix/vector U and V based on the loss function\n",
        "    \"\"\"\n",
        "    global U, V\n",
        "    pred = forward(word_indices)\n",
        "    prob = pred[\"prob\"]\n",
        "    h = pred[\"h\"]\n",
        "    hid = pred[\"hid\"]\n",
        "\n",
        "    # update U and V here\n",
        "    # loss_function = y * log(o) + (1 - y) * log(1 - o)\n",
        "    #               = true_label * log(prob) + (1 - true_label) * log(1 - prob)\n",
        "    # to update V: V_new = V_current + d(loss_function)/d(V)*alpha\n",
        "    # to update U: U_new = U_current + d(loss_function)/d(U)*alpha\n",
        "    # Make sure you only update the appropriate argmax term for U\n",
        "    \"\"\"\n",
        "    Type your code below\n",
        "    \"\"\"\n",
        "    # update U \n",
        "    for f in range(F):\n",
        "      update_U = U\n",
        "      #max_p = (1 - h[f]**2)\n",
        "      #grad_U = ((true_label - prob)* (V[f]) * max_p\n",
        "      #grad_U = U[word_indices[hid[f]], f, 0] + ((true_label - prob)* (V[f]) * max_p\n",
        "      #U += grad_U * alpha \n",
        "      #U[word_indices[hid[f]], f, 0] = U[word_indices[hid[f]], f, 0] + grad_U * alpha\n",
        "      #U[word_indices[hid[f] + 1], f, 1] = U[word_indices[hid[f] + 1], f, 1] + grad_U * alpha\n",
        "\n",
        "      update_U[word_indices[hid[f]], f, 0] = U[word_indices[hid[f]], f, 0] + ((true_label - prob)* (V[f]) * (1 - h[f]**2)) * alpha\n",
        "      update_U[word_indices[hid[f] + 1], f, 1] = U[word_indices[hid[f] + 1], f, 1] + ((true_label - prob)* (V[f]) * (1 - h[f]**2)) * alpha\n",
        "\n",
        "    # update V\n",
        "    update_V = V + ((true_label - prob)*(h)) * alpha\n",
        "\n",
        "    U = update_U\n",
        "    V = update_V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciTgokCwILqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sanity_check():\n",
        "  for i in range(1000):\n",
        "    prob_neg = forward([0, 0, 0, 1, 2, 3, 4])[\"prob\"]\n",
        "    prob_pos = forward([0, 0, 0, 5, 6, 0, 8, 9])[\"prob\"]\n",
        "    backward([0, 1, 2, 3, 4], 0)\n",
        "    backward([5, 6, 7, 8, 9], 1)\n",
        "    if i % 100 == 0:\n",
        "      print(f'should be 0 {prob_neg}, should be 1 {prob_pos}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbqWZRjUIPRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b04f0f0e-202b-4539-c37b-d4603f8fbc5f"
      },
      "source": [
        "sanity_check()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "should be 0 0.5003372393708465, should be 1 0.500812057816792\n",
            "should be 0 0.030231305025029204, should be 1 0.8512066360863532\n",
            "should be 0 0.009942773069676026, should be 1 0.9065625679504438\n",
            "should be 0 0.005815658079525226, should be 1 0.9258772335386258\n",
            "should be 0 0.004088089024183816, should be 1 0.9364850112970592\n",
            "should be 0 0.0031467029262147936, should be 1 0.9434190608061221\n",
            "should be 0 0.0025560089125541297, should be 1 0.9484133659478635\n",
            "should be 0 0.002151480379669377, should be 1 0.9522303761865052\n",
            "should be 0 0.0018574138153097095, should be 1 0.9552703504406833\n",
            "should be 0 0.0016340517815027168, should be 1 0.9577687186225252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atJ7itphH0U_",
        "colab_type": "text"
      },
      "source": [
        "Once you have implemented both the forward and backward functions, your can test out your implementations by training the model. To do so, run the `train` function in the cell below. If your implementations are correct, you should see the accuracy improve as the model trains (You will be graded based on the correctness of the implementations, not on this accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S8d23Uf5K9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "5318a0f8-58e6-48b3-feed-7603dcabf3b5"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tDev accuracy: 0.610\n",
            "Epoch: 1 \tDev accuracy: 0.688\n",
            "Epoch: 2 \tDev accuracy: 0.730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-db5e09c26036>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# calculate forward and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mconfusion_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a3b045bdd762>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(word_indices)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# index U to create p_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# for k in range(width):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}